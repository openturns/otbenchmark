{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark on a given set of problems\n",
    "\n",
    "In this example, we show how to make a loop over the problems in the benchmark. We also show how to run various reliability algorithms on a given problem so that we can score the methods using number of digits or performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "import numpy as np\n",
    "import otbenchmark as otb\n",
    "import openturns.viewer as otv\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse the reliability problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the BBRC test cases using the otbenchmark module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkProblemList = otb.ReliabilityBenchmarkProblemList()\n",
    "numberOfProblems = len(benchmarkProblemList)\n",
    "numberOfProblems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 0 : RP8  : pf =  0.000784 , dimension= 6\n",
      "# 1 : RP14  : pf =  0.00752 , dimension= 5\n",
      "# 2 : RP22  : pf =  0.00416 , dimension= 2\n",
      "# 3 : RP24  : pf =  0.00286 , dimension= 2\n",
      "# 4 : RP25  : pf =  6.14e-06 , dimension= 2\n",
      "# 5 : RP28  : pf =  1.46e-07 , dimension= 2\n",
      "# 6 : RP31  : pf =  0.00018 , dimension= 2\n",
      "# 7 : RP33  : pf =  0.00257 , dimension= 3\n",
      "# 8 : RP35  : pf =  0.00354 , dimension= 2\n",
      "# 9 : RP38  : pf =  0.0081 , dimension= 7\n",
      "# 10 : RP53  : pf =  0.0313 , dimension= 2\n",
      "# 11 : RP55  : pf =  0.36 , dimension= 2\n",
      "# 12 : RP54  : pf =  0.000998 , dimension= 20\n",
      "# 13 : RP57  : pf =  0.0284 , dimension= 2\n",
      "# 14 : RP75  : pf =  0.0107 , dimension= 2\n",
      "# 15 : RP89  : pf =  0.00543 , dimension= 2\n",
      "# 16 : RP107  : pf =  2.92e-07 , dimension= 10\n",
      "# 17 : RP110  : pf =  3.19e-05 , dimension= 2\n",
      "# 18 : RP111  : pf =  7.65e-07 , dimension= 2\n",
      "# 19 : RP63  : pf =  0.000379 , dimension= 100\n",
      "# 20 : RP91  : pf =  0.000697 , dimension= 5\n",
      "# 21 : RP60  : pf =  0.0456 , dimension= 5\n",
      "# 22 : RP77  : pf =  2.87e-07 , dimension= 3\n",
      "# 23 : Four-branch serial system (Waarts, 2000)  : pf =  0.0021859614549132322 , dimension= 2\n",
      "# 24 : R-S  : pf =  0.07864960352514257 , dimension= 2\n",
      "# 25 : Axial stressed beam  : pf =  0.029198194624830955 , dimension= 2\n"
     ]
    }
   ],
   "source": [
    "for i in range(numberOfProblems):\n",
    "    problem = benchmarkProblemList[i]\n",
    "    name = problem.getName()\n",
    "    pf = problem.getProbability()\n",
    "    event = problem.getEvent()\n",
    "    antecedent = event.getAntecedent()\n",
    "    distribution = antecedent.getDistribution()\n",
    "    dimension = distribution.getDimension()\n",
    "    print(\"#\", i, \":\", name, \" : pf = \", pf, \", dimension=\", dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximumEvaluationNumber = 1000\n",
    "maximumAbsoluteError = 1.0e-3\n",
    "maximumRelativeError = 1.0e-3\n",
    "maximumResidualError = 1.0e-3\n",
    "maximumConstraintError = 1.0e-3\n",
    "nearestPointAlgorithm = ot.AbdoRackwitz()\n",
    "nearestPointAlgorithm.setMaximumCallsNumber(maximumEvaluationNumber)\n",
    "nearestPointAlgorithm.setMaximumAbsoluteError(maximumAbsoluteError)\n",
    "nearestPointAlgorithm.setMaximumRelativeError(maximumRelativeError)\n",
    "nearestPointAlgorithm.setMaximumResidualError(maximumResidualError)\n",
    "nearestPointAlgorithm.setMaximumConstraintError(maximumConstraintError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The FORM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = otb.ReliabilityProblem8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaAlgorithm = otb.ReliabilityBenchmarkMetaAlgorithm(problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computedProbability = 0.000659887791408224  exactProbability = 0.000784  absoluteError = 0.00012411220859177602 numberOfCorrectDigits = 0.8005015586776216 numberOfFunctionEvaluations = 7numberOfDigitsPerEvaluation = 0.11435736552537452'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkResult = metaAlgorithm.runFORM(nearestPointAlgorithm)\n",
    "benchmarkResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SORM method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computedProbability = 0.0007838036444007566  exactProbability = 0.000784  absoluteError = 1.9635559924335248e-07 numberOfCorrectDigits = 3.60127277263278 numberOfFunctionEvaluations = 7numberOfDigitsPerEvaluation = 0.5144675389475399'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkResult = metaAlgorithm.runSORM(nearestPointAlgorithm)\n",
    "benchmarkResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LHS method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computedProbability = 0.0012000000000000116  exactProbability = 0.000784  absoluteError = 0.00041600000000001163 numberOfCorrectDigits = 0.27522273205768355 numberOfFunctionEvaluations = 10000numberOfDigitsPerEvaluation = 2.7522273205768354e-05'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkResult = metaAlgorithm.runLHS(maximumOuterSampling=10000)\n",
    "benchmarkResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MonteCarloSampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computedProbability = 0.0003000000000000004  exactProbability = 0.000784  absoluteError = 0.00048399999999999957 numberOfCorrectDigits = 0.2094707010400263 numberOfFunctionEvaluations = 10000numberOfDigitsPerEvaluation = 2.0947070104002628e-05'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkResult = metaAlgorithm.runMonteCarlo(maximumOuterSampling=10000)\n",
    "benchmarkResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The FORM - Importance Sampling method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computedProbability = 0.0008185203661905634  exactProbability = 0.000784  absoluteError = 3.4520366190563456e-05 numberOfCorrectDigits = 1.3562406686396002 numberOfFunctionEvaluations = 409numberOfDigitsPerEvaluation = 0.0033159918548645484'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkResult = metaAlgorithm.runFORMImportanceSampling(nearestPointAlgorithm)\n",
    "benchmarkResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Subset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computedProbability = 0.0006124000000000045  exactProbability = 0.000784  absoluteError = 0.0001715999999999955 numberOfCorrectDigits = 0.6597987791717631 numberOfFunctionEvaluations = 20000numberOfDigitsPerEvaluation = 3.298993895858815e-05'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkResult = metaAlgorithm.runSubsetSampling()\n",
    "benchmarkResult.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the number of correct base-10 digits in the computed result compared to the exact result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `CompareMethods` function takes as a parameter a problem and it returns the probabilities estimated by each method. In addition, it returns the performance of these methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrintResults(name, benchmarkResult):\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(name)\n",
    "    numberOfDigitsPerEvaluation = (\n",
    "        benchmarkResult.numberOfCorrectDigits\n",
    "        / benchmarkResult.numberOfFunctionEvaluations\n",
    "    )\n",
    "    print(\"Estimated probability:\", benchmarkResult.computedProbability)\n",
    "    print(\"Number of function calls:\", benchmarkResult.numberOfFunctionEvaluations)\n",
    "    print(\"Number of correct digits=%.1f\" % (benchmarkResult.numberOfCorrectDigits))\n",
    "    print(\n",
    "        \"Performance=%.2e (correct digits/evaluation)\" % (numberOfDigitsPerEvaluation)\n",
    "    )\n",
    "    return [name, benchmarkResult.numberOfCorrectDigits, numberOfDigitsPerEvaluation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareMethods(problem, nearestPointAlgorithm, maximumOuterSampling=10000):\n",
    "    \"\"\"\n",
    "    Runs various algorithms on a given problem.\n",
    "    \"\"\"\n",
    "    summaryList = []\n",
    "    pfReference = problem.getProbability()\n",
    "    print(\"Exact probability:\", pf)\n",
    "    metaAlgorithm = otb.ReliabilityBenchmarkMetaAlgorithm(problem)\n",
    "    # SubsetSampling\n",
    "    benchmarkResult = metaAlgorithm.runSubsetSampling()\n",
    "    summaryList.append(PrintResults(\"SubsetSampling\", benchmarkResult))\n",
    "    # FORM\n",
    "    benchmarkResult = metaAlgorithm.runFORM(nearestPointAlgorithm)\n",
    "    summaryList.append(PrintResults(\"FORM\", benchmarkResult))\n",
    "    # SORM\n",
    "    benchmarkResult = metaAlgorithm.runSORM(nearestPointAlgorithm)\n",
    "    summaryList.append(PrintResults(\"SORM\", benchmarkResult))\n",
    "    # FORM - ImportanceSampling\n",
    "    benchmarkResult = metaAlgorithm.runFORMImportanceSampling(\n",
    "        nearestPointAlgorithm, maximumOuterSampling=maximumOuterSampling\n",
    "    )\n",
    "    summaryList.append(PrintResults(\"FORM-IS\", benchmarkResult))\n",
    "    # MonteCarloSampling\n",
    "    benchmarkResult = metaAlgorithm.runMonteCarlo(\n",
    "        maximumOuterSampling=maximumOuterSampling\n",
    "    )\n",
    "    summaryList.append(PrintResults(\"MonteCarloSampling\", benchmarkResult))\n",
    "    # LHS\n",
    "    benchmarkResult = metaAlgorithm.runLHS()\n",
    "    summaryList.append(PrintResults(\"LHS\", benchmarkResult))\n",
    "    # Gather results\n",
    "    numberOfMethods = len(summaryList)\n",
    "    correctDigitsList = []\n",
    "    performanceList = []\n",
    "    algorithmNames = []\n",
    "    for i in range(numberOfMethods):\n",
    "        [name, numberOfCorrectDigits, numberOfDigitsPerEvaluation] = summaryList[i]\n",
    "        algorithmNames.append(name)\n",
    "        correctDigitsList.append(numberOfCorrectDigits)\n",
    "        performanceList.append(numberOfDigitsPerEvaluation)\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Scoring by number of correct digits\")\n",
    "    indices = np.argsort(correctDigitsList)\n",
    "    rank = list(indices)\n",
    "    for i in range(numberOfMethods):\n",
    "        j = rank[i]\n",
    "        print(\"%d : %s (%.1f)\" % (j, algorithmNames[j], correctDigitsList[j]))\n",
    "    print(\"------------------------------------------------------------------------\")\n",
    "    print(\"Scoring by performance (digits/evaluation)\")\n",
    "    indices = np.argsort(performanceList)\n",
    "    rank = list(indices)\n",
    "    for i in range(len(indices)):\n",
    "        j = rank[i]\n",
    "        print(\"%d : %s (%.1e)\" % (j, algorithmNames[j], performanceList[j]))\n",
    "    return correctDigitsList, performanceList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact probability: 0.029198194624830955\n",
      "------------------------------------------------------------------\n",
      "SubsetSampling\n",
      "Estimated probability: 0.0007298\n",
      "Number of function calls: 20000\n",
      "Number of correct digits=1.2\n",
      "Performance=5.80e-05 (correct digits/evaluation)\n",
      "------------------------------------------------------------------\n",
      "FORM\n",
      "Estimated probability: 0.000659887791408224\n",
      "Number of function calls: 7\n",
      "Number of correct digits=0.8\n",
      "Performance=1.14e-01 (correct digits/evaluation)\n",
      "------------------------------------------------------------------\n",
      "SORM\n",
      "Estimated probability: 0.0007838036444007566\n",
      "Number of function calls: 7\n",
      "Number of correct digits=3.6\n",
      "Performance=5.14e-01 (correct digits/evaluation)\n",
      "------------------------------------------------------------------\n",
      "FORM-IS\n",
      "Estimated probability: 0.0006733813101400115\n",
      "Number of function calls: 415\n",
      "Number of correct digits=0.9\n",
      "Performance=2.05e-03 (correct digits/evaluation)\n",
      "------------------------------------------------------------------\n",
      "MonteCarloSampling\n",
      "Estimated probability: 0.0003999999999999998\n",
      "Number of function calls: 10000\n",
      "Number of correct digits=0.3\n",
      "Performance=3.10e-05 (correct digits/evaluation)\n",
      "------------------------------------------------------------------\n",
      "LHS\n",
      "Estimated probability: 0.0009999999999999985\n",
      "Number of function calls: 1000\n",
      "Number of correct digits=0.6\n",
      "Performance=5.60e-04 (correct digits/evaluation)\n",
      "------------------------------------------------------------------------\n",
      "Scoring by number of correct digits\n",
      "4 : MonteCarloSampling (0.3)\n",
      "5 : LHS (0.6)\n",
      "1 : FORM (0.8)\n",
      "3 : FORM-IS (0.9)\n",
      "0 : SubsetSampling (1.2)\n",
      "2 : SORM (3.6)\n",
      "------------------------------------------------------------------------\n",
      "Scoring by performance (digits/evaluation)\n",
      "4 : MonteCarloSampling (3.1e-05)\n",
      "0 : SubsetSampling (5.8e-05)\n",
      "5 : LHS (5.6e-04)\n",
      "3 : FORM-IS (2.0e-03)\n",
      "1 : FORM (1.1e-01)\n",
      "2 : SORM (5.1e-01)\n"
     ]
    }
   ],
   "source": [
    "problem = otb.ReliabilityProblem8()\n",
    "_ = CompareMethods(problem, nearestPointAlgorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarks\n",
    "\n",
    "* We note that the FORM and SORM methods are faster, but, they do not converge to the exact proba.\n",
    "* We also notice the effectiveness of the FORM-ImportanceSampling method (inexpensive method, and converges).\n",
    "* The convergence of the MonteCarlo method requires a large number of simulations.\n",
    "* SubsetSampling converges even if the probability is very low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
